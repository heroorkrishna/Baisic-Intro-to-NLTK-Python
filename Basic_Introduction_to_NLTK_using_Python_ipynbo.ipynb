{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic Introduction to NLTK using Python.ipynbo ",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiUotbaI6pdJ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPC1jn1V6rnc",
        "colab_type": "text"
      },
      "source": [
        "**NLTK - Natural Language ToolKit**\n",
        "\n",
        "By using NLTK we will be performing some Natural Language Programming \n",
        "\n",
        "1. NLTK Tokenize\n",
        "2. Removing stop words\n",
        "3. Stemming NLTK\n",
        "4. Finding synonyms, antonyms and other stuffs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWMlb_C68PXP",
        "colab_type": "text"
      },
      "source": [
        "Lets begin \n",
        "\n",
        "What is NLTK?\n",
        "\n",
        "As mentioned above it is Natural Language Toolkit\n",
        "\n",
        "What's this toolkit is used for?\n",
        "\n",
        "NLTK is a suite of libraries and programs for statistical and symbolic NLP for English Lan...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VW0RRLl39dpU",
        "colab_type": "text"
      },
      "source": [
        "STEP 1: Installing the required package and library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YqinJaj7Awr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "00bfa5ad-a85a-42f6-fb34-ea84d5dba5db"
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se4zRWf-97oo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f8cc86d9-d917-4674-9cf2-7724149fa278"
      },
      "source": [
        "import nltk\n",
        "nltk.download()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuytNUL5_VaS",
        "colab_type": "text"
      },
      "source": [
        "**1. NLTK Tokenize**\n",
        "\n",
        "Tokenize text splits into small parts like \n",
        "- paragraphs to sentences\n",
        "- sentences to words\n",
        "\n",
        "There are two kinds of tokenizers for both sentence and words\n",
        "\n",
        "**1. NLTK sentence Tokenizer**\n",
        "\n",
        "**2. NLTK words Tokenizer**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbP9mokl-TbD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1. NLTK sentence Tokenizer\n",
        "\n",
        "text = 'Today is a normal day. It is not better than yesterday. And yesterday was the best day ever.'\n",
        "text2 = \"Hey, how are you? I'm good, you? Fine!\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjxBMGLTAqy6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e905be5a-3bf2-408d-f9de-7bd8568672fc"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "print(sent_tokenize(text))\n",
        "print(sent_tokenize(text2))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Today is a normal day.', 'It is not better than yesterday.', 'And yesterday was the best day ever.']\n",
            "['Hey, how are you?', \"I'm good, you?\", 'Fine!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5OIfSM4BJg-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "c45ecee4-e848-4978-f980-14dd859fc3f9"
      },
      "source": [
        "#2. NLTK word Tokenizer\n",
        "\n",
        "print(nltk.word_tokenize(text))\n",
        "print(nltk.word_tokenize(text2))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Today', 'is', 'a', 'normal', 'day', '.', 'It', 'is', 'not', 'better', 'than', 'yesterday', '.', 'And', 'yesterday', 'was', 'the', 'best', 'day', 'ever', '.']\n",
            "['Hey', ',', 'how', 'are', 'you', '?', 'I', \"'m\", 'good', ',', 'you', '?', 'Fine', '!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoiwaqlfBuX0",
        "colab_type": "text"
      },
      "source": [
        "**2. Removing stopwords**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGjKIupaB-xV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "text = \"Today is a normal day. It is not better than yesterday. And yesterday was the best day ever!\"\n",
        "stopwords=set(stopwords.words('english'))\n",
        "from nltk.tokenize import word_tokenize\n",
        "words = word_tokenize(text)\n",
        "w = []\n",
        "for i in words:\n",
        "    if i not in stopwords:\n",
        "        w.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ymYzawNCYYq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "427797a0-0c6e-4c25-dcce-4c352b079635"
      },
      "source": [
        "print(w)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Today', 'normal', 'day', '.', 'It', 'better', 'yesterday', '.', 'And', 'yesterday', 'best', 'day', 'ever', '!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vYmojUMCkyV",
        "colab_type": "text"
      },
      "source": [
        "**3. STEMMING NLTK**\n",
        "\n",
        "What is stemming?\n",
        "\n",
        "Removing afflixes from the word and returning the root. Most of the search engines use for efficiently index pages.\n",
        "Most used algorithms for stemming is **porterstemmer**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtnUv1-TDwI9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "49ffd83c-b0f5-40df-d7e3-dbb08072f692"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "ps.stem('hard working')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hard work'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc4_YgjxEoVJ",
        "colab_type": "text"
      },
      "source": [
        "More algorithms for stemming Lancaster and Snowbal\n",
        "\n",
        "**snowball stemmer** - is an algorithm for suffix stripping\n",
        "\n",
        "**Lancaster** - this algorithm will reduce different forms of word to a core root\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_8A1aLGGRej",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "416c4ce4-ca49-465f-a387-5168e68d850f"
      },
      "source": [
        "#using snowballstemmer\n",
        "\n",
        "from nltk.stem import SnowballStemmer\n",
        "SnowballStemmer.languages"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('arabic',\n",
              " 'danish',\n",
              " 'dutch',\n",
              " 'english',\n",
              " 'finnish',\n",
              " 'french',\n",
              " 'german',\n",
              " 'hungarian',\n",
              " 'italian',\n",
              " 'norwegian',\n",
              " 'porter',\n",
              " 'portuguese',\n",
              " 'romanian',\n",
              " 'russian',\n",
              " 'spanish',\n",
              " 'swedish')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gatZnaYmGneQ",
        "colab_type": "text"
      },
      "source": [
        "**4.NLTK Synonyms and Antonyms**\n",
        "\n",
        "synonyms from WordNet\n",
        "\n",
        "**WordNet** - It is a NLP database with all synonyms, antonyms and other brief definiytions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtR_W8zdKZck",
        "colab_type": "text"
      },
      "source": [
        "**4.(a) NLTK Synonyms using wordnet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxqLE7qbHRac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import wordnet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck6Arw6sGd7j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fefd335e-5835-4af5-8578-91913582394b"
      },
      "source": [
        "word = wordnet.synsets('success')\n",
        "print(word)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Synset('success.n.01'), Synset('success.n.02'), Synset('success.n.03'), Synset('achiever.n.01')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhXFyMy6IOo0",
        "colab_type": "text"
      },
      "source": [
        "To get the definition of the word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoiTxylQIMZN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "af309424-bbd4-4801-d2c9-529864c5131a"
      },
      "source": [
        "print(word[0].definition())\n",
        "# for example\n",
        "print(word[0].examples())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "an event that accomplishes its intended purpose\n",
            "[\"let's call heads a success and tails a failure\", 'the election was a remarkable success for the Whigs']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9k9YbOII6cJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ab300b29-aa64-4db9-d8d8-b5687f03032c"
      },
      "source": [
        "word1 = wordnet.synsets('Engineering')\n",
        "word1"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('technology.n.01'),\n",
              " Synset('engineering.n.02'),\n",
              " Synset('engineering.n.03'),\n",
              " Synset('engineer.v.01'),\n",
              " Synset('mastermind.v.01')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYmq45fuJNNE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6122a76c-4e6d-41ef-9406-426e714b899e"
      },
      "source": [
        "print(word1[1].definition())\n",
        "# for example\n",
        "print(word1[1].examples())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the discipline dealing with the art or science of applying scientific knowledge to practical problems\n",
            "['he had trouble deciding which branch of engineering to study']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9f63JdcJxAK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4493512-cbbc-4277-9be0-4415a46f6962"
      },
      "source": [
        "# to get the list of synonyms\n",
        "synonys = []\n",
        "for sys in wordnet.synsets('NLP'):\n",
        "    for a in sys.lemmas():\n",
        "        synonys.append(a.name())\n",
        "        \n",
        "synonys"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['natural_language_processing', 'NLP', 'human_language_technology']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXMyVYpiJ9fo",
        "colab_type": "text"
      },
      "source": [
        "**4.(b) NLTK Antonyms using wordnet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTxyTrK7Kn_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "antonyms = []\n",
        "for sys in wordnet.synsets('success'):\n",
        "    for l in sys.lemmas():\n",
        "        if l.antonyms():\n",
        "            antonyms.append(l.antonyms()[0].name())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxpD9aB2Ku6C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "50707413-a8bf-4557-dd09-6bd721a6c938"
      },
      "source": [
        "print(antonyms)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['failure', 'failure', 'loser']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xah1JmdmGlkX",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}